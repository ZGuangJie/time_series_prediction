# æ—¶åºæ•°æ®é¢„æµ‹ä¹‹èˆ¹èˆ¶ä½ç½®é¢„æµ‹ 

## ğŸ“‹ é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªåŸºäºPyTorchçš„å®Œæ•´ã€å¯æ‰©å±•çš„èˆ¹èˆ¶ä½ç½®é¢„æµ‹ç³»ç»Ÿï¼Œé‡‡ç”¨é¢å‘å¯¹è±¡è®¾è®¡ï¼Œæ”¯æŒå¤šç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆLSTMã€GRUã€Transformerï¼‰è¿›è¡Œæ—¶åºé¢„æµ‹ã€‚è¯¥é¡¹ç›®é’ˆå¯¹"ç”¨ç»åº¦ã€çº¬åº¦ã€èˆªé€Ÿã€èˆªå‘é¢„æµ‹èˆ¹èˆ¶ä½ç½®"çš„éœ€æ±‚ï¼Œæ„å»ºäº†å¤šå˜é‡æ—¶åºå›å½’æ¨¡å‹ã€‚

### æ ¸å¿ƒç‰¹æ€§

- âœ… **å®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹**ï¼šæ•°æ®åŠ è½½ã€æ¸…æ´—ã€å¼‚å¸¸å€¼å¤„ç†ã€ç¼ºå¤±å€¼å¡«å……ã€æ ‡å‡†åŒ–
- âœ… **å¤šç§æ¨¡å‹æ”¯æŒ**ï¼šLSTMã€GRUã€Transformerï¼ˆæ˜“äºæ‰©å±•ï¼‰
- âœ… **GPUåŠ é€Ÿè®­ç»ƒ**ï¼šå®Œå…¨æ”¯æŒCUDAåŠ é€Ÿ
- âœ… **çµæ´»çš„é…ç½®ç³»ç»Ÿ**ï¼šåŸºäºYAMLçš„é…ç½®æ–‡ä»¶ï¼Œæ˜“äºè°ƒæ•´å‚æ•°
- âœ… **å…¨é¢çš„è¯„ä¼°æŒ‡æ ‡**ï¼šMAEã€RMSEã€MAPEã€RÂ²ã€åœ°ç†è·ç¦»è¯¯å·®ç­‰
- âœ… **é²æ£’æ€§æµ‹è¯•**ï¼šå™ªå£°å¹²æ‰°ä¸‹çš„æ€§èƒ½è¯„ä¼°
- âœ… **å¯è§†åŒ–å·¥å…·**ï¼šè®­ç»ƒå†å²ã€é¢„æµ‹ç»“æœã€è½¨è¿¹å¯¹æ¯”ç­‰
- âœ… **ç”Ÿäº§å°±ç»ª**ï¼šåŒ…å«è®­ç»ƒã€é¢„æµ‹ã€è¯„ä¼°å®Œæ•´æµç¨‹

---

## ğŸ—ï¸ é¡¹ç›®ç»“æ„

```
time_series_prediction/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml              # é…ç½®æ–‡ä»¶
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # åŸå§‹æ•°æ®ç›®å½•
â”‚   â”‚   â””â”€â”€ ship_data.csv        # èˆ¹èˆ¶AISæ•°æ®
â”‚   â””â”€â”€ processed/               # å¤„ç†åæ•°æ®
â”‚       â””â”€â”€ preprocessor.pkl     # é¢„å¤„ç†å™¨ï¼ˆè®­ç»ƒåç”Ÿæˆï¼‰
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py            # åŸºç¡€æ¨¡å‹ç±»
â”‚   â”œâ”€â”€ lstm_model.py            # LSTM/GRUæ¨¡å‹
â”‚   â””â”€â”€ transformer_model.py     # Transformeræ¨¡å‹
â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py           # æ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ preprocessor.py          # æ•°æ®é¢„å¤„ç†å™¨
â”‚   â””â”€â”€ feature_engineer.py      # ç‰¹å¾å·¥ç¨‹
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py               # è®­ç»ƒå™¨
â”‚   â””â”€â”€ evaluator.py             # è¯„ä¼°å™¨
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py               # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ visualization.py         # å¯è§†åŒ–å·¥å…·
â”œâ”€â”€ checkpoints/                 # æ¨¡å‹æ£€æŸ¥ç‚¹ç›®å½•
â”œâ”€â”€ logs/                        # æ—¥å¿—ç›®å½•
â”œâ”€â”€ runs/                        # TensorBoardæ—¥å¿—
â”œâ”€â”€ results/                     # ç»“æœè¾“å‡ºç›®å½•
â”œâ”€â”€ train.py                     # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ predict.py                   # é¢„æµ‹è„šæœ¬
â”œâ”€â”€ generate_sample_data.py      # ç¤ºä¾‹æ•°æ®ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ requirements.txt             # ä¾èµ–åŒ…
â””â”€â”€ README.md                    # é¡¹ç›®æ–‡æ¡£
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®

#### åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨conda
conda create -n ship_prediction python=3.10
conda activate ship_prediction

# æˆ–ä½¿ç”¨venv
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
```

#### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. å‡†å¤‡æ•°æ®

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨ç¤ºä¾‹æ•°æ®ç”Ÿæˆè„šæœ¬

```bash
python generate_sample_data.py
```

è¿™å°†ç”Ÿæˆä¸€ä¸ªç¤ºä¾‹èˆ¹èˆ¶AISæ•°æ®æ–‡ä»¶ `data/raw/ship_data.csv`ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- `longitude`: ç»åº¦
- `latitude`: çº¬åº¦
- `speed`: èˆªé€Ÿï¼ˆèŠ‚ï¼‰
- `course`: èˆªå‘ï¼ˆåº¦ï¼‰

#### æ–¹å¼äºŒï¼šä½¿ç”¨è‡ªå·±çš„æ•°æ®

å°†CSVæ•°æ®æ–‡ä»¶æ”¾ç½®åœ¨ `data/raw/` ç›®å½•ä¸‹ï¼Œç¡®ä¿åŒ…å«ä»¥ä¸‹åˆ—ï¼š
- `longitude`, `latitude`, `speed`, `course`

æ•°æ®æ ¼å¼ç¤ºä¾‹ï¼š

```csv
longitude,latitude,speed,course
121.5000,31.2000,15.5,45.0
121.5010,31.2008,15.3,44.5
121.5020,31.2016,15.8,44.0
...
```

### 3. é…ç½®æ¨¡å‹

ç¼–è¾‘ `config/config.yaml` æ–‡ä»¶ï¼Œæ ¹æ®éœ€æ±‚è°ƒæ•´å‚æ•°ï¼š

```yaml
# é€‰æ‹©æ¨¡å‹ç±»å‹
model:
  model_type: "LSTM"  # å¯é€‰: LSTM, GRU, Transformer

# è°ƒæ•´è®­ç»ƒå‚æ•°
training:
  batch_size: 64
  num_epochs: 100
  learning_rate: 0.001
  device: "cuda"  # æˆ– "cpu"
```

### 4. è®­ç»ƒæ¨¡å‹

```bash
python train.py --config config/config.yaml
```

è®­ç»ƒè¿‡ç¨‹å°†ï¼š
- è‡ªåŠ¨åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼ˆ70%/20%/10%ï¼‰
- å®æ—¶æ˜¾ç¤ºè®­ç»ƒè¿›åº¦å’ŒæŒ‡æ ‡
- ä¿å­˜æœ€ä½³æ¨¡å‹åˆ° `checkpoints/best_model.pth`
- ç”ŸæˆTensorBoardæ—¥å¿—åˆ° `runs/`
- ä¿å­˜è®­ç»ƒå†å²å›¾åˆ° `results/training_history.png`

#### æŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ï¼ˆTensorBoardï¼‰

```bash
tensorboard --logdir=runs/
```

### 5. æ¨¡å‹è¯„ä¼°ä¸é¢„æµ‹

```bash
# ä»æ–‡ä»¶é¢„æµ‹
python predict.py \
    --config config/config.yaml \
    --model_path checkpoints/best_model.pth \
    --mode file \
    --input_file data/raw/ship_data.csv \
    --output_file results/predictions.csv \
    --visualize
```

é¢„æµ‹ç»“æœå°†åŒ…å«ï¼š
- é¢„æµ‹çš„ç»çº¬åº¦åæ ‡
- è¯„ä¼°æŒ‡æ ‡ï¼ˆMAEã€RMSEç­‰ï¼‰
- å¯è§†åŒ–å›¾è¡¨ï¼ˆ`--visualize`é€‰é¡¹ï¼‰

---

## ğŸ“Š æ¨¡å‹æ¶æ„

### LSTMæ¨¡å‹

```
è¾“å…¥: (batch_size, 6, 4)  # 6ä¸ªæ—¶é—´æ­¥ï¼Œ4ä¸ªç‰¹å¾
  â†“
LSTMå±‚1 (hidden_size=64)
  â†“
Batch Normalization
  â†“
Dropout (0.2)
  â†“
LSTMå±‚2 (hidden_size=32)
  â†“
Dropout (0.2)
  â†“
å…¨è¿æ¥å±‚
  â†“
è¾“å‡º: (batch_size, 3, 2)  # 3ä¸ªæ—¶é—´æ­¥ï¼Œ2ä¸ªç›®æ ‡ï¼ˆç»åº¦ã€çº¬åº¦ï¼‰
```

### Transformeræ¨¡å‹

```
è¾“å…¥: (batch_size, 6, 4)
  â†“
è¾“å…¥åµŒå…¥ (input_dim â†’ d_model)
  â†“
ä½ç½®ç¼–ç 
  â†“
Transformerç¼–ç å™¨ (å¤šå±‚)
  â†“
è§£ç å™¨ (å…¨è¿æ¥)
  â†“
è¾“å‡º: (batch_size, 3, 2)
```

---

## ğŸ”§ è¯¦ç»†ä½¿ç”¨æŒ‡å—

### æ•°æ®é¢„å¤„ç†

é¡¹ç›®å®ç°äº†å®Œæ•´çš„æ•°æ®é¢„å¤„ç†æµç¨‹ï¼š

1. **å¼‚å¸¸å€¼å¤„ç†**
   - èˆªé€Ÿé™åˆ¶ï¼š0-30èŠ‚ï¼ˆå¯é…ç½®ï¼‰
   - ç»åº¦ï¼š-180Â°è‡³180Â°
   - çº¬åº¦ï¼š-90Â°è‡³90Â°

2. **ç¼ºå¤±å€¼å¡«å……**
   - `forward`ï¼šå‰å‘å¡«å……
   - `interpolate`ï¼šä¸‰æ¬¡æ’å€¼ï¼ˆæ¨èï¼‰

3. **æ ‡å‡†åŒ–æ–¹æ³•**
   - `zscore`ï¼šZ-scoreæ ‡å‡†åŒ–ï¼ˆæ¨èï¼‰
   - `minmax`ï¼šMin-Maxå½’ä¸€åŒ–

### æ¨¡å‹é…ç½®

#### LSTMé…ç½®ç¤ºä¾‹

```yaml
model:
  model_type: "LSTM"
  lstm:
    hidden_size: 64      # éšè—å±‚å¤§å°
    num_layers: 2        # LSTMå±‚æ•°
    dropout: 0.2         # Dropoutæ¯”ä¾‹
    bidirectional: false # æ˜¯å¦åŒå‘
```

#### Transformeré…ç½®ç¤ºä¾‹

```yaml
model:
  model_type: "Transformer"
  transformer:
    d_model: 64          # æ¨¡å‹ç»´åº¦
    nhead: 4             # æ³¨æ„åŠ›å¤´æ•°
    num_layers: 2        # Transformerå±‚æ•°
    dim_feedforward: 256 # å‰é¦ˆç½‘ç»œç»´åº¦
    dropout: 0.2
```

### è®­ç»ƒé…ç½®

```yaml
training:
  batch_size: 64           # æ‰¹æ¬¡å¤§å°
  num_epochs: 100          # è®­ç»ƒè½®æ•°
  learning_rate: 0.001     # å­¦ä¹ ç‡
  weight_decay: 0.001      # L2æ­£åˆ™åŒ–
  
  # ä¼˜åŒ–å™¨é€‰æ‹©
  optimizer: "adam"        # adam, adamw, sgd
  
  # å­¦ä¹ ç‡è°ƒåº¦å™¨
  scheduler:
    type: "ReduceLROnPlateau"
    patience: 10
    factor: 0.5
  
  # æ—©åœé…ç½®
  early_stopping:
    patience: 20
    min_delta: 0.0001
  
  # æŸå¤±å‡½æ•°
  loss_function: "weighted_mse"  # mse, mae, huber, weighted_mse
  time_step_weights: [1.0, 0.8, 0.6]  # æ—¶é—´æ­¥æƒé‡ï¼ˆè¿‘æœŸæƒé‡é«˜ï¼‰
```

### è¯„ä¼°æŒ‡æ ‡è¯´æ˜

| æŒ‡æ ‡ | è¯´æ˜ | ç›®æ ‡å€¼ |
|------|------|--------|
| **MAE** | å¹³å‡ç»å¯¹è¯¯å·® | < 0.005åº¦ï¼ˆçº¦550ç±³ï¼‰ |
| **RMSE** | å‡æ–¹æ ¹è¯¯å·® | < 0.01åº¦ï¼ˆçº¦1.1å…¬é‡Œï¼‰ |
| **MAPE** | å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® | < 5% |
| **RÂ²** | å†³å®šç³»æ•° | > 0.95 |
| **Distance Error** | åœ°ç†è·ç¦»è¯¯å·®ï¼ˆkmï¼‰ | < 1.0å…¬é‡Œ |

---

## ğŸ“ˆ é«˜çº§åŠŸèƒ½

### 1. é²æ£’æ€§æµ‹è¯•

è¯„ä¼°æ¨¡å‹åœ¨å™ªå£°å¹²æ‰°ä¸‹çš„æ€§èƒ½ï¼š

```python
# åœ¨config.yamlä¸­å¯ç”¨
evaluation:
  robustness_test:
    enabled: true
    noise_level: 0.5  # èˆªé€Ÿå™ªå£°Â±0.5èŠ‚
```

### 2. æŒ‰æ—¶é—´æ­¥è¯„ä¼°

åˆ†æä¸åŒé¢„æµ‹æ­¥é•¿çš„è¯¯å·®å˜åŒ–ï¼š

```bash
# è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨è¿›è¡ŒæŒ‰æ—¶é—´æ­¥è¯„ä¼°
python train.py
```

### 3. æ¨ç†æ—¶é—´æµ‹é‡

è¯„ä¼°æ¨¡å‹çš„å®æ—¶æ€§èƒ½ï¼š

- å•æ ·æœ¬æ¨ç†æ—¶é—´
- æ‰¹é‡æ¨ç†ååé‡

ç›®æ ‡ï¼šå•æ ·æœ¬æ¨ç† < 10ms

### 4. è‡ªå®šä¹‰æŸå¤±å‡½æ•°

å®ç°äº†åŠ æƒMSEæŸå¤±ï¼Œè¿‘æœŸæ—¶é—´æ­¥æƒé‡æ›´é«˜ï¼š

```yaml
training:
  loss_function: "weighted_mse"
  time_step_weights: [1.0, 0.8, 0.6]  # ç¬¬1ã€2ã€3æ­¥çš„æƒé‡
```

---

## ğŸ¯ æ¨¡å‹é€‰æ‹©å»ºè®®

| åœºæ™¯ | æ¨èæ¨¡å‹ | åŸå›  |
|------|----------|------|
| **çŸ­æœŸé¢„æµ‹**ï¼ˆ< 30åˆ†é’Ÿï¼‰ | LSTM | è®­ç»ƒå¿«ã€æ•ˆæœå¥½ã€èµ„æºå ç”¨å° |
| **é•¿æœŸé¢„æµ‹**ï¼ˆ> 1å°æ—¶ï¼‰ | Transformer | æ›´å¥½çš„é•¿åºåˆ—å»ºæ¨¡èƒ½åŠ› |
| **å®æ—¶æ¨ç†** | GRU | æ¯”LSTMæ›´å¿«ï¼Œæ€§èƒ½ç›¸è¿‘ |
| **å°æ ·æœ¬æ•°æ®** | LSTM | å‚æ•°å°‘ï¼Œä¸æ˜“è¿‡æ‹Ÿåˆ |
| **å¤§è§„æ¨¡æ•°æ®** | Transformer | å¯å¹¶è¡Œè®­ç»ƒï¼Œå……åˆ†åˆ©ç”¨æ•°æ® |

---

## ğŸ’¡ æ‰©å±•å¼€å‘

### æ·»åŠ æ–°æ¨¡å‹

1. åœ¨ `models/` ç›®å½•åˆ›å»ºæ–°æ¨¡å‹æ–‡ä»¶
2. ç»§æ‰¿ `BaseTimeSeriesModel` ç±»
3. å®ç° `forward` æ–¹æ³•
4. åœ¨ `train.py` å’Œ `predict.py` ä¸­æ³¨å†Œæ¨¡å‹

ç¤ºä¾‹ï¼š

```python
# models/my_model.py
from models.base_model import BaseTimeSeriesModel

class MyModel(BaseTimeSeriesModel):
    def __init__(self, input_dim, output_dim, lookback_window, prediction_window):
        super().__init__(input_dim, output_dim, lookback_window, prediction_window)
        # å®šä¹‰æ¨¡å‹ç»“æ„
        
    def forward(self, x):
        # å®ç°å‰å‘ä¼ æ’­
        return output
```

### æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡

åœ¨ `utils/metrics.py` ä¸­æ·»åŠ æ–°å‡½æ•°ï¼š

```python
def calculate_new_metric(y_true, y_pred):
    # å®ç°æ–°æŒ‡æ ‡
    return metric_value
```

### è‡ªå®šä¹‰æ•°æ®å¤„ç†

ä¿®æ”¹ `preprocessing/preprocessor.py` ä¸­çš„æ–¹æ³•æˆ–æ·»åŠ æ–°æ–¹æ³•ã€‚

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: CUDA out of memory

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å‡å° `batch_size`ï¼ˆå¦‚ä»64é™åˆ°32ï¼‰
- å‡å°æ¨¡å‹å¤§å°ï¼ˆ`hidden_size`ï¼‰
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

### Q2: è®­ç»ƒæŸå¤±ä¸ä¸‹é™

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥å­¦ä¹ ç‡ï¼ˆå°è¯•0.0001ï¼‰
- æ£€æŸ¥æ•°æ®æ ‡å‡†åŒ–æ˜¯å¦æ­£ç¡®
- å¢åŠ è®­ç»ƒè½®æ•°
- å°è¯•å…¶ä»–ä¼˜åŒ–å™¨ï¼ˆAdamWï¼‰

### Q3: è¿‡æ‹Ÿåˆé—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š
- å¢åŠ Dropoutæ¯”ä¾‹ï¼ˆ0.3-0.5ï¼‰
- å¢åŠ L2æ­£åˆ™åŒ–ï¼ˆweight_decayï¼‰
- ä½¿ç”¨æ•°æ®å¢å¼º
- å‡å°‘æ¨¡å‹å¤æ‚åº¦

### Q4: é¢„æµ‹ç»“æœåå·®å¤§

**è§£å†³æ–¹æ¡ˆ**ï¼š
- æ£€æŸ¥æ•°æ®è´¨é‡å’Œå¼‚å¸¸å€¼
- å¢åŠ è®­ç»ƒæ•°æ®é‡
- è°ƒæ•´é¢„æµ‹çª—å£é•¿åº¦
- å°è¯•ä¸åŒçš„æ¨¡å‹æ¶æ„

### Q5: ä¸­æ–‡å­—ä½“è­¦å‘Š (Glyph missing from font)

**ç°è±¡**ï¼š
```
UserWarning: Glyph 35757 (\N{CJK UNIFIED IDEOGRAPH-8BAD}) missing from font(s) DejaVu Sans.
```

**åŸå› **ï¼šmatplotlib é»˜è®¤å­—ä½“ä¸æ”¯æŒä¸­æ–‡å­—ç¬¦

**è§£å†³æ–¹æ¡ˆ**ï¼š
- âœ… **å·²è‡ªåŠ¨é…ç½®**ï¼šé¡¹ç›®å·²åœ¨ `utils/visualization.py` ä¸­è‡ªåŠ¨é…ç½®ä¸­æ–‡å­—ä½“
- è­¦å‘Šä¸å½±å“ä½¿ç”¨ï¼Œå›¾ç‰‡ä¸­çš„ä¸­æ–‡ä¼šæ­£å¸¸æ˜¾ç¤º
- å¦‚éœ€å®Œå…¨æ¶ˆé™¤è­¦å‘Šï¼Œè¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯ï¼š
  ```bash
  python test_chinese_font.py
  ```
- è¯¦ç»†è¯´æ˜è¯·æŸ¥çœ‹ï¼š`docs/FONT_SETUP.md`

**Windowsç”¨æˆ·**ï¼šç³»ç»Ÿè‡ªå¸¦å¾®è½¯é›…é»‘å­—ä½“ï¼Œæ— éœ€é¢å¤–é…ç½®

**Linuxç”¨æˆ·**ï¼šå¦‚éœ€å®‰è£…ä¸­æ–‡å­—ä½“
```bash
# Ubuntu/Debian
sudo apt-get install fonts-wqy-microhei

# CentOS/RHEL  
sudo yum install wqy-microhei-fonts
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### ç›¸å…³è®ºæ–‡

1. **LSTM**: Hochreiter & Schmidhuber (1997). Long Short-Term Memory
2. **Transformer**: Vaswani et al. (2017). Attention Is All You Need
3. **Time Series Forecasting**: Lim et al. (2021). Temporal Fusion Transformers

### æŠ€æœ¯æ–‡æ¡£

- [PyTorchå®˜æ–¹æ–‡æ¡£](https://pytorch.org/docs/)
- [æ—¶åºé¢„æµ‹æœ€ä½³å®è·µ](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-10-24)

- âœ… åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- âœ… æ”¯æŒLSTMã€GRUã€Transformeræ¨¡å‹
- âœ… å®Œæ•´çš„è®­ç»ƒå’Œé¢„æµ‹æµç¨‹
- âœ… å…¨é¢çš„è¯„ä¼°å’Œå¯è§†åŒ–å·¥å…·

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºå»ºè®®ï¼

1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯Pull Request

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§LICENSEæ–‡ä»¶

---

## ğŸ‘¥ ä½œè€…

- é¡¹ç›®å¼€å‘ï¼šChuanguang Zhu
- æŠ€æœ¯æ”¯æŒï¼šæ¬¢è¿æäº¤Issue

---

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®çš„æ”¯æŒï¼š

- PyTorch
- NumPy & Pandas
- Matplotlib
- TensorBoard

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š

- æäº¤Issue: [GitHub Issues](https://github.com/ZGuangJie/time_series_prediction/issues)
- é‚®ä»¶: Guangjie98@outlook.com

---

**Happy Predicting! ğŸš¢âš“**

